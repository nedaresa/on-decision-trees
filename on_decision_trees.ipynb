{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On Decision Trees\n",
    "\n",
    "Let's do a simple internet image search for decision trees.\n",
    "\n",
    "What does this have to do with data science?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install python-graphviz -y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-Giving conditions to predict an outcome\n",
    "-Questions whose answers depend on multiple factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A decision tree is a machine learning model that works by *partitioning* our sample space in a hierarchical way.\n",
    "\n",
    "*How* do we partition the space? The key idea is that some attributes provide more *information* than others when trying to make a decision.\n",
    "\n",
    "## Motivating Example\n",
    "\n",
    "Suppose a friend said to you: \"Hey, you have experience predicting housing prices! I'm hoping you can predict what my house will sell for.\"\n",
    "\n",
    "What are the top questions you would ask about your friend's house? Let's make a list:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-where is it\n",
    "-how big is it\n",
    "-how many bedrooms\n",
    "-how old is it\n",
    "-in what condition is it\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now: *Why* are these questions good questions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-these answers have a great impact on price."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Bit More Detail\n",
    "\n",
    "Suppose that we work for a retail company and that we're working on a classification model that can predict whether customers will pay their bills or not. In effect what we want to do is to ask questions that will *sort* our customers into two classes: (i) those who pay and (ii) those who don't.\n",
    "\n",
    "**If I ask enough data-dividing questions, I can produce a partition of my data such that, in each subset, either (i) everyone is a payer or (ii) everyone is a non-payer.**\n",
    "\n",
    "Each row in my dataframe represents a customer, and I have many predictors (columns) in my dataframe, including:\n",
    "\n",
    "- salary\n",
    "- total_bill\n",
    "- club_member (boolean)\n",
    "- years_post-sec_ed\n",
    "\n",
    "Let's look at a simple set of data. **The 'paid' column is our target or dependent variable.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "custs = pd.DataFrame([[45000, 1000, True, 2, False], [70000, 100, True, 10, True],\n",
    "             [30000, 2000, False, 0, False], [90000, 500, True, 2, True],\n",
    "             [70000, 200, True, 5, False]],\n",
    "            columns=['salary', 'total_bill', 'club_member', 'years_post-sec_ed',\n",
    "                    'paid'])\n",
    "custs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partitioning\n",
    "\n",
    "I partition my data by asking a question about the independent variables. The goal is to ask the right questions in the right order so that the resultant groups are \"pure\" with respect to the dependent variable. More on this below!\n",
    "\n",
    "Suppose, for example, that I choose:\n",
    "\n",
    "### Is the customer a club member?\n",
    "\n",
    "This would divide my data into two groups:\n",
    "\n",
    "- Group 1 (club_member = True):\n",
    "\n",
    "data points: 0, 1, 3, 4\n",
    "\n",
    "- Group 2 (club_member = False):\n",
    "\n",
    "data points: 2\n",
    "\n",
    "#### Key Question: How are the values of the target distributed in this group?\n",
    "In Group 1, I have, in order: non-payer, payer, payer, non-payer.\n",
    "\n",
    "In Group 2, I have a single non-payer.\n",
    "\n",
    "While I've isolated one of the customers who haven't paid in the second group, the first group is an even mix of payers and non-payers. So this split is not particularly good.\n",
    "\n",
    "Would a different question split our data more effectively? Let's try:\n",
    "\n",
    "### \"Is the customer's salary less than $60k?\"\n",
    "\n",
    "This would divide my data into two groups:\n",
    "\n",
    "- Group 1 (salary < 60000):\n",
    "\n",
    "data points: 0, 2\n",
    "\n",
    "-  Group 2 (salary $\\geq$ 60000):\n",
    "\n",
    "data points: 1, 3, 4\n",
    "\n",
    "#### Key Question: How are the values of the target distributed in this group?\n",
    "In Group 1, I have two non-payers.\n",
    "\n",
    "In Group 2, I have, in order: payer, payer, non-payer.\n",
    "\n",
    "This does a better job of partitioning my data according to the values of the dependent variable: The first group contains only customers who have not paid their bills, and the second group contains only one customer who has not paid her bill.\n",
    "\n",
    "So a (very simple!) model that predicts:\n",
    "(i) that customers who make less than \\$60k *won't* pay their bill, and\n",
    "(ii) that customers who make $60k or more *will* pay their bill\n",
    "\n",
    "would perform fairly well.\n",
    "\n",
    "But how would my partition be *best* split? And how do I really know that the second split is better than the first? Can I do better than intuition here?\n",
    "\n",
    "## Entropy and Information Gain\n",
    "\n",
    "The goal is to have our ultimate classes be fully \"ordered\" (for a binary dependent variable, we'd have the 1's in one group and the 0's in the other). So one way to assess the value of a split is to measure how *disordered* our groups are, and there is a notion of *entropy* that measures precisely this.\n",
    "\n",
    "The entropy of the whole dataset is given by:\n",
    "\n",
    "$\\large E = -\\Sigma^n_i p_i\\log_2(p_i)$,\n",
    "\n",
    "where $p_i$ is the probability of belonging to the $i$th group, where $n$ is the number of groups (i.e. target values).\n",
    "\n",
    "**Entropy will always be between 0 and 1. The closer to 1, the more disordered your group.**\n",
    "\n",
    "To repeat, in the present case we have only two groups of interest: the payers and the non-payers.\n",
    "\n",
    "Two out of five are payers and three out of five are non-payers, so **these are the relevant probabilities** for our calculation of entropy.\n",
    "\n",
    "So our entropy for this toy dataset is:\n",
    "\n",
    "$-0.4*\\log_2(0.4) -0.6*\\log_2(0.6)$.\n",
    "\n",
    "Let's use the ```math``` library to calculate this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log\n",
    "\n",
    "# Your code here!\n",
    "\n",
    "ent_whole = -0.4*log(0.4,2) -0.6*log(0.6,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's pretty disordered!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the entropy of a *split*, we're going to want to calculate the entropy of each of the groups made by the split, and then calculate a weighted average of those groups' entropies––weighted, that is, by the size of the groups. Let's calculate the entropy of the split produced by our question above about salary:\n",
    "\n",
    "Group 1:\n",
    "\n",
    "$E_{g1} = - 1 * \\log_2(1) = 0$. This is a pure group! The probability of being a payer in Group 1 is 0 and the probability of being a non-payer in Group 1 is 1.\n",
    "\n",
    "Group 2:\n",
    "\n",
    "$E_{g2} = \\frac{2}{3} * \\log_2\\left(\\frac{2}{3}\\right) - \\frac{1}{3} * \\log_2\\left(\\frac{1}{3}\\right)$.\n",
    "\n",
    "Once again, using ```math```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here!\n",
    "\n",
    "ent_grp2 = -(2/3)*log(2/3,2)-(1/3)*log(1/3,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the whole entropy for this split, we'll do a weighted sum of the two group entropies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here!\n",
    "\n",
    "0.4*0+0.6*ent_grp2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a given split, the **information gain** is simply the entropy of the parent group less the entropy of the split.\n",
    "\n",
    "For a given parent, then, we maximize our model's performance by *minimizing* the split's entropy.\n",
    "\n",
    "What we'd like to do then is:\n",
    "\n",
    "1. to look at the entropies of all possible splits, and\n",
    "2. to choose the split with the lowest entropy.\n",
    "\n",
    "In practice there are far too many splits for it to be practical for a person to calculate all these different entropies ...\n",
    "\n",
    "... but we can make computers do these calculations for us!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gini Impurity\n",
    "\n",
    "An alternative metric to entropy comes from the work of Corrado Gini. The Gini Impurity is defined as:\n",
    "\n",
    "$\\large G = 1 - \\Sigma_i p_i^2$,\n",
    "\n",
    "where, again, $p_i$ is the probability of belonging to the $i$th group.\n",
    "\n",
    "**Gini Impurity will always be between 0 and 0.5. The closer to 0.5, the more disordered your group.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise: Calculate the Gini Impurity for our toy dataset above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coding Trees in Python\n",
    "\n",
    "Scikit-learn has a tree module, which houses both a DecisionTreeClassifier and a DecisionTreeRegressor. As is probably clear by now, is that the former is for classification problems (discrete target) and the latter is for regression problems (continuous target). Let's use the classifier.\n",
    "\n",
    "(Of course, the regressor can't quite work the same way as detailed here! For more details on this, see [here](https://www.saedsayad.com/decision_tree_reg.htm) and [here](https://acadgild.com/blog/using-decision-trees-for-regression-problems).)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = DecisionTreeClassifier() # Check out all the\n",
    "                              # hyperparameter options here!\n",
    "\n",
    "ct.fit(custs.drop('paid', axis=1), custs['paid'])\n",
    "ct.score(custs.drop('paid', axis=1), custs['paid'])    \n",
    "#score is measure of accuracy and shows how many points are truly classified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus\n",
    "from sklearn.externals.six import StringIO\n",
    "from IPython.display import Image\n",
    "\n",
    "dot_file = StringIO()\n",
    "\n",
    "export_graphviz(ct, out_file=dot_file, filled=True,\n",
    "               rounded=True)\n",
    "\n",
    "image=pydotplus.graph_from_dot_data(dot_file.getvalue())\n",
    "Image(image.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct.tree_.node_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_nodes = ct.tree_.node_count\n",
    "children_left = ct.tree_.children_left\n",
    "children_right = ct.tree_.children_right\n",
    "feature = ct.tree_.feature\n",
    "threshold = ct.tree_.threshold\n",
    "\n",
    "# This code courtesy of sklearn:\n",
    "# https://scikit-learn.org/stable/auto_examples/tree/plot_unveil_tree_structure.html\n",
    "\n",
    "\n",
    "# The tree structure can be traversed to compute various properties such\n",
    "# as the depth of each node and whether or not it is a leaf.\n",
    "node_depth = np.zeros(shape=n_nodes, dtype=np.int64)\n",
    "is_leaves = np.zeros(shape=n_nodes, dtype=bool)\n",
    "stack = [(0, -1)]  # seed is the root node id and its parent depth\n",
    "while len(stack) > 0:\n",
    "    node_id, parent_depth = stack.pop()\n",
    "    node_depth[node_id] = parent_depth + 1\n",
    "\n",
    "    # If we have a test node\n",
    "    if (children_left[node_id] != children_right[node_id]):\n",
    "        stack.append((children_left[node_id], parent_depth + 1))\n",
    "        stack.append((children_right[node_id], parent_depth + 1))\n",
    "    else:\n",
    "        is_leaves[node_id] = True\n",
    "\n",
    "print(\"The binary tree structure has %s nodes and has \"\n",
    "      \"the following tree structure:\"\n",
    "      % n_nodes)\n",
    "for i in range(n_nodes):\n",
    "    if is_leaves[i]:\n",
    "        print(\"%snode=%s leaf node.\" % (node_depth[i] * \"\\t\", i))\n",
    "    else:\n",
    "        print(\"%snode=%s test node: go to node %s if X[:, %s] <= %s else to \"\n",
    "              \"node %s.\"\n",
    "              % (node_depth[i] * \"\\t\",\n",
    "                 i,\n",
    "                 children_left[i],\n",
    "                 feature[i],\n",
    "                 threshold[i],\n",
    "                 children_right[i],\n",
    "                 ))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "Let's unpack this:\n",
    "\n",
    "The first question (\"test\") is: \"Is Salary $\\leq$ 57500?\" If so, then stop: All such customers (i.e. customers 0 and 2) are *non-payers*. Notice how 57500 is midway between the salaries of customer 0 (45000, a non-payer) and customers 1 and 4 (70000, payers).\n",
    "\n",
    "If not: The next test (for those whose salary > 57500) is: \"Is Total Bill $\\leq$ 150?\" If so, then stop: All such customers (i.e. customer 1) are *payers*. Notice how 150 is midway between the total bills of customer 1 (100, a payer) and customer 4 (200, a non-payer).\n",
    "\n",
    "If not: The next test (for those whose total bill > 150) is: \"Is Salary $\\leq$ 80000?\" If so, then stop: All such customers (i.e. customer 3) are *non-payers*. If not, then stop: All such customers (i.e. customer 4) are *payers*. Notice how 3.5 is midway between the numbers of years of post-sec ed of customer 3 (90000, a payer) and customer 4 (70000, a non-payer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct.tree_.children_left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct.tree_.children_right"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
